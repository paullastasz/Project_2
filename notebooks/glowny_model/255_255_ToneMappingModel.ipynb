{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["BV82fOKRLPbd"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Konfiguracja\n","Przed uruchomieniem należy sprawdzic sciezki i odpowiednio ustawic stałe"],"metadata":{"id":"agkSqqzQmjys"}},{"cell_type":"code","source":["MAIN_FOLDER = '/content/drive/MyDrive'\n","\n","data_folder = MAIN_FOLDER + '/data/prepared' # zip z plikami ref i input\n","\n","# INPUT_95_DATASET_FOLDER = '/content/input_95_dataset'\n","REFERENCE_DATASET_FOLDER = '/content/reference_dataset'\n","INPUT_97_DATASET_FOLDER = '/content/input_97_dataset'\n","\n","RESULTS_FOLDER = \"/content/drive/MyDrive/SIGK_P2/resultsV5\" # folder w którym będą obrazki wyjściowe z treningu oraz z testu (w podfolderze /TEST)\n","CHECKPOINTS_FOLDER = \"/content/drive/MyDrive/SIGK_P2/checkpoints\"\n","\n","COMPARE_FOLDER = '/content/drive/MyDrive/SIGK_P2/compareV5'"],"metadata":{"id":"94GexAafmlLV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["unzip_files = False # czy wypakowywac pliki (z data_folder do DATASET_FOLDER)"],"metadata":{"id":"dXwpq6uEsQ6s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_model = False # czy trenować model (konfiguracja w sekcji Trening)"],"metadata":{"id":"GZfdsC3_0ORo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_model = False # czy testować model (zapisac pliki wyjsciowe do folderu)\n","#PRZED TESTOWANIEM KONIECZNIE WCZYTAJ WAGI MODELU (CHECKPOINT) - nie korzysta z tego samego modelu co w treningu"],"metadata":{"id":"r8qL-xqT02tG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calc_metrics = False # czy wyliczac metryki"],"metadata":{"id":"iHKOJHvK5EH2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Moduły"],"metadata":{"id":"ekmMzUSqlFxF"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EJoFfhpb-pwi","outputId":"f7f61c79-d61f-434c-c6ee-ec5ac9815910"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install brisque"],"metadata":{"id":"V8yypNmvW-4L","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fad25f42-2822-45ac-e22e-c919dc4291d0","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting brisque\n","  Downloading brisque-0.0.17-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from brisque) (2.0.2)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from brisque) (0.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from brisque) (1.16.3)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from brisque) (4.12.0.88)\n","Collecting libsvm-official (from brisque)\n","  Downloading libsvm-official-3.36.0.tar.gz (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from brisque) (2.32.4)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->brisque) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->brisque) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->brisque) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->brisque) (2025.10.5)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->brisque) (3.5)\n","Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image->brisque) (11.3.0)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->brisque) (2.37.2)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->brisque) (2025.10.16)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->brisque) (25.0)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->brisque) (0.4)\n","Downloading brisque-0.0.17-py3-none-any.whl (140 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: libsvm-official\n","  Building wheel for libsvm-official (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for libsvm-official: filename=libsvm_official-3.36.0-cp312-cp312-linux_x86_64.whl size=124638 sha256=77a4e1597aa23bfbb2a28dcd4c46cd16faee360ddab70f961a39f8197e3f94ed\n","  Stored in directory: /root/.cache/pip/wheels/df/65/4b/c3cdece6e5fa7eebef116be2d5a309f7ac50c90183cbe12c92\n","Successfully built libsvm-official\n","Installing collected packages: libsvm-official, brisque\n","Successfully installed brisque-0.0.17 libsvm-official-3.36.0\n"]}]},{"cell_type":"code","source":["import zipfile\n","import os\n","import glob"],"metadata":{"id":"2kqIi0K0mWpB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import models, transforms\n","import torch.nn.functional as F\n","import numpy as np"],"metadata":{"id":"Optmc1Pnmc5X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","from numpy import ndarray\n","from brisque import BRISQUE\n","from skimage.metrics import structural_similarity as ssim"],"metadata":{"id":"pS-MBNWAxmT_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datetime import datetime"],"metadata":{"id":"Ddmnh2-HzP3u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from google.colab.patches import cv2_imshow"],"metadata":{"id":"8qqBi1bGtY1Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Funkcje pomocnicze - metryki oraz przygotowanie plików"],"metadata":{"id":"uUYeAtiqmrFC"}},{"cell_type":"markdown","source":["## Rozpakowanie archiwum"],"metadata":{"id":"xlGN3yfomtUh"}},{"cell_type":"code","source":["def unzip(source_path, target_path, with_main_folder=True):\n","  if os.path.exists(source_path):\n","    os.makedirs(target_path, exist_ok=True)\n","\n","    with zipfile.ZipFile(source_path, 'r') as zip_ref:\n","      if with_main_folder:\n","        zip_ref.extractall(target_path)\n","      else:\n","        for content in zip_ref.namelist():\n","          name_archive = content.split('/', 1)[0]\n","          content = content.split('/', 1)[-1] if '/' in content else content\n","\n","          if content == '' or content == '/':\n","            continue\n","\n","          with zip_ref.open(name_archive + '/' + content) as source, open(os.path.join(target_path, content), \"wb\") as target:\n","            target.write(source.read())\n","\n","    print(f'File unziped: source={source_path}, target={target_path}')\n","  else:\n","    print(f'Cannot unzip (file not found): source={source_path}, target={target_path}')"],"metadata":{"id":"SSIhiro5m0Z0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Operacje na plikach EXR i operatory"],"metadata":{"id":"eKGqDSNJ2KL8"}},{"cell_type":"code","source":[" # enable using OpenEXR with OpenCV\n"," os.environ['OPENCV_IO_ENABLE_OPENEXR'] = \"1\""],"metadata":{"id":"RmD1VPf0FmCu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def read_exr(im_path: str)-> ndarray:\n","  return cv2.imread(\n","  filename=im_path,\n","  flags=cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH\n","  )"],"metadata":{"id":"9YioGOAR2PI9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tone_map_reinhard(image: ndarray)-> ndarray:\n","  tonemap_operator = cv2.createTonemapReinhard(\n","  gamma=2.2,\n","  intensity=0.0,\n","  light_adapt=0.0,\n","  color_adapt=0.0\n","  )\n","  result = tonemap_operator.process(src=image)\n","  return result"],"metadata":{"id":"EXf4WsCI2VjJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tone_map_mantiuk(image: ndarray)-> ndarray:\n","  tonemap_operator = cv2.createTonemapMantiuk(\n","  gamma=2.2,\n","  scale=0.85,\n","  saturation=1.2\n","  )\n","  result = tonemap_operator.process(src=image)\n","  return result"],"metadata":{"id":"qHankfoj2cGA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Metryka BRISQUE"],"metadata":{"id":"BV82fOKRLPbd"}},{"cell_type":"code","source":["def evaluate_image(image: ndarray)-> float:\n"," metric = BRISQUE(url=False)\n"," return metric.score(img=image)"],"metadata":{"id":"MpcDuiqO2gZo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Wczytanie danych"],"metadata":{"id":"YJFTAlwblKeL"}},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"id":"awwRLrECnIzK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f838ffef-7699-4cf5-a7aa-aae5e2898d80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["data_folder_contents = os.listdir(data_folder)\n","\n","print(f\"Zawartość folderu {data_folder}: {data_folder_contents}\")"],"metadata":{"id":"hUi62o8ynK9i","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b684a0bc-67d1-4715-c1d1-8e18a1bbddc3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Zawartość folderu /content/drive/MyDrive/data/prepared: ['reference.zip', 'input_97.zip', 'input_95.zip']\n"]}]},{"cell_type":"code","source":["if unzip_files:\n","  reference_path = data_folder + '/reference.zip'\n","  unzip(reference_path, REFERENCE_DATASET_FOLDER, False)\n","\n","  input_97_path = data_folder + '/input_97.zip'\n","  unzip(input_97_path, INPUT_97_DATASET_FOLDER, False)\n","\n","  ref_files = sorted(os.listdir(REFERENCE_DATASET_FOLDER))\n","  print(f\"Unzipped reference dataset, total files: {len(ref_files)}\")"],"metadata":{"id":"qcfOuRID0IPX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6e4fa3ce-f439-4d58-cbaf-8ccf409a7eb9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["File unziped: source=/content/drive/MyDrive/data/prepared/reference.zip, target=/content/reference_dataset\n","File unziped: source=/content/drive/MyDrive/data/prepared/input_97.zip, target=/content/input_97_dataset\n","Unzipped reference dataset, total files: 181\n"]}]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"oKMbDa79lV1X"}},{"cell_type":"markdown","source":["## Helpery, dataset, zapisywanie rezultatu/utils"],"metadata":{"id":"OztHI-prlQ1k"}},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"metadata":{"id":"16XYtnryuLZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------- helpery dla sieci --------------------\n","def norm(x):\n","    x_max = np.max(x)\n","    x_min = np.min(x)\n","    scale = x_max - x_min\n","    x_norm = (x - x_min)/scale\n","    return x_norm\n","\n","def norm_mean(img):\n","    img = 0.5 * img / img.mean()\n","    return img\n","\n","def ulaw_np(img, scale = 10.0):\n","    median_value = np.median(img)\n","    scale = 8.759 * np.power(median_value, 2.148) + 0.1494 * np.power(median_value, -2.067)\n","    out = np.log(1 + scale*img) / np.log(1 + scale)\n","    return out.astype(np.float32), scale\n","\n","def load_hdr_ldr_norm_ulaw(name_hdr):\n","    y = read_exr(name_hdr)\n","    y = cv2.resize(y, (255, 255), interpolation=cv2.INTER_AREA) # operujemy na 255vs255\n","    y_rgb = np.maximum(cv2.cvtColor(y, cv2.COLOR_BGR2RGB), 0.0)\n","    y_rgb = norm_mean(y_rgb)\n","    y_ulaw, scale = ulaw_np(y_rgb)\n","    return scale, y_ulaw, y_rgb"],"metadata":{"id":"fUJv91HVtl2l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------- DATASET --------------------\n","class HDRDataset(Dataset):\n","    def __init__(self, hdr_folder, limit=None, from_file=None):\n","        self.files = [os.path.join(hdr_folder, f) for f in os.listdir(hdr_folder) if f.endswith('.exr')]\n","        self.files.sort()\n","        if from_file:\n","            self.files = self.files[from_file:]\n","        if limit:\n","            self.files = self.files[:limit]\n","\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def __getitem__(self, idx):\n","        hdr_file = self.files[idx]\n","        scale, hdr_ulaw, hdr_rgb = load_hdr_ldr_norm_ulaw(hdr_file)\n","\n","        # do Pytorch: (C,H,W)\n","        hdr_ulaw = torch.from_numpy(hdr_ulaw).permute(2,0,1)\n","        hdr_rgb   = torch.from_numpy(hdr_rgb).permute(2,0,1)\n","\n","        return hdr_ulaw, hdr_rgb, hdr_file"],"metadata":{"id":"xd--Z3mGttXP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------- UTIL dla sieci --------------------\n","\n","def mul_exp(img):\n","    # img: (B,C,H,W)\n","    B,C,H,W = img.shape\n","\n","    x_p = 1.21497\n","\n","    max_val = img.view(B,-1).max(dim=1)[0].view(B,1,1,1)\n","    med_val = img.view(B,-1).median(dim=1)[0].view(B,1,1,1)\n","\n","    c_start = torch.log(x_p / max_val) / torch.log(torch.tensor(2.0))\n","    c_end = torch.log(x_p / med_val) / torch.log(torch.tensor(2.0))\n","\n","    exp_values = [c_start, (c_start + c_end)/2.0, c_end]\n","\n","    output_list = []\n","    for c in exp_values:\n","        sc = (2.0**0.5) ** c\n","\n","        img_out = img * sc\n","        img_out = torch.clamp(img_out, 0.0, 1.0)\n","        output_list.append(img_out)\n","\n","    return output_list\n","\n","def writeLDR(img, path):\n","    if isinstance(img, torch.Tensor):\n","        img = img.detach().cpu().numpy()\n","\n","    # (C,H,W) -> (H,W,C)\n","    img = np.transpose(img, (1,2,0))\n","\n","    # clamp i 0-255\n","    img = np.clip(img, 0.0, 1.0)\n","    img = (img * 255).astype(np.uint8)\n","\n","    # RGB -> BGR dla OpenCV\n","    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n","    cv2.imwrite(path, img)"],"metadata":{"id":"LkYZN6m9ttgm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Architektura sieci"],"metadata":{"id":"Rbxlz8vUuf8_"}},{"cell_type":"code","source":["# -------------------- NETWORK --------------------\n","class Encoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3,16,3,padding=1)\n","        self.conv2 = nn.Conv2d(16,32,3,padding=1)\n","        self.conv3 = nn.Conv2d(32,64,3,padding=1)\n","    def forward(self,x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = F.relu(self.conv3(x))\n","        return x\n","\n","class Decoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(64,32,3,padding=1)\n","        self.conv2 = nn.Conv2d(32,16,3,padding=1)\n","        self.conv3 = nn.Conv2d(16,3,3,padding=1)\n","    def forward(self,x, img1,img2,img3):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = self.conv3(x)\n","        x = torch.sigmoid(x + img1 + img2 + img3)\n","        return x\n","\n","class TMONet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.encoder = Encoder()\n","        self.decoder = Decoder()\n","        # fusion convs\n","        self.fusion_conv1 = nn.Conv2d(64*3, 64, 3, padding=1) # zmniejszone ze względu na zbyt duze uzycie RAM w porowaniu do oryginalnej arhcitektury\n","        self.fusion_conv2 = nn.Conv2d(64, 64, 1)\n","\n","    def forward(self, i0, i1, i2):\n","        # encode each input\n","        o0 = self.encoder(i0)\n","        o1 = self.encoder(i1)\n","        o2 = self.encoder(i2)\n","\n","        # concat features\n","        o0 = torch.cat([o0, o1, o2], dim=1) # nadpisywanie dla optymalizacji wykorzystania RAM\n","        o1 = o2 = None\n","\n","        # fusion block\n","        o0 = F.relu(self.fusion_conv1(o0))\n","\n","        o0 = self.fusion_conv2(o0)\n","\n","        # decode\n","        o0 = self.decoder(o0, i0, i1, i2)\n","        return o0"],"metadata":{"id":"sMCRbbcZSsbf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Funkcja straty"],"metadata":{"id":"YO-5sLBiukg_"}},{"cell_type":"code","source":["# ---------------------------\n","# VGG feature extractor\n","vgg_model = models.vgg19(pretrained=True).features.to(device).eval()\n","for p in vgg_model.parameters():\n","    p.requires_grad = False\n","\n","def vgg_features(x, layers=['0','5','10']):  # odpowiada VGG11,21,31 w TF\n","    features = []\n","    h = x\n","    for idx, layer in enumerate(vgg_model):\n","        h = layer(h)\n","        if str(idx) in layers:\n","            features.append(h)\n","    return features  # lista tensorow\n","\n","# ---------------------------\n","# Gaussian kernel\n","_gaussian_cache = {} # optymalizacja aby raz wczytac\n","def gaussian_kernel(size=13, sigma=2.0, channels=3, device='cpu'):\n","    key = (size, sigma, channels)\n","    if key in _gaussian_cache:\n","        return _gaussian_cache[key].to(device)\n","    coords = np.arange(size) - size//2\n","    x, y = np.meshgrid(coords, coords)\n","    kernel = np.exp(-(x**2 + y**2)/(2*sigma**2))\n","    kernel = kernel / kernel.sum()\n","    kernel = torch.tensor(kernel, dtype=torch.float32, device=device)\n","    kernel = kernel.view(1,1,size,size).repeat(channels,1,1,1)\n","    _gaussian_cache[key] = kernel\n","    return kernel\n","\n","def local_mean_std(x, kernel_size=13, sigma=2.0):\n","    C = x.shape[1]\n","    w = gaussian_kernel(kernel_size, sigma, C).to(x.device)\n","    x_pad = F.pad(x, (kernel_size//2,)*4, mode='reflect')\n","    mean_local = F.conv2d(x_pad, w, groups=C)\n","    mean_sq = F.conv2d(x_pad**2, w, groups=C)\n","    std_local = torch.sqrt(torch.clamp(mean_sq - mean_local**2, min=1e-8))\n","    return mean_local, std_local\n","\n","# ---------------------------\n","# Feature contrast masking\n","def sign_num_den(x, gamma=0.5, beta=0.5, sigma=2.0, kernel_size=13):\n","    mean_local, std_local = local_mean_std(x, kernel_size, sigma)\n","    norm_num = torch.sign(x - mean_local) * torch.abs((x - mean_local)/(mean_local.abs()+1e-8))**gamma\n","    norm_den = 1.0 + (std_local / (mean_local.abs()+1e-8))**beta\n","    return norm_num, norm_den\n","\n","def feature_contrast_masking(x, gamma=0.5, beta=0.5, sigma=2.0, kernel_size=13):\n","    num, den = sign_num_den(x, gamma, beta, sigma, kernel_size)\n","    return num / den\n","\n","def masking_loss(pred, target, gamma=0.5, beta=0.5, sigma=2.0, kernel_size=13):\n","    f_pred = feature_contrast_masking(pred, gamma=1.0, beta=beta, sigma=sigma, kernel_size=kernel_size)\n","    f_target = feature_contrast_masking(target, gamma=gamma, beta=beta, sigma=sigma, kernel_size=kernel_size)\n","    return F.l1_loss(f_pred, f_target)\n","\n","# ---------------------------\n","# FCM loss\n","def fcm_loss(pred, target, gamma=0.5, beta=0.5, sigma=2.0, kernel_size=13):\n","    feats_pred = vgg_features(pred, layers=['0','5','10'])   # odpowiada VGG11,21,31\n","    with torch.no_grad():\n","      feats_target = vgg_features(target, layers=['0','5','10'])\n","    loss_total = 0.0\n","    for f_pred, f_target in zip(feats_pred, feats_target):\n","        loss_total += masking_loss(f_pred, f_target, gamma=gamma, beta=beta, sigma=sigma, kernel_size=kernel_size)\n","    loss_total /= len(feats_pred)\n","    return loss_total"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d7NBFDdUSzrS","outputId":"c5820982-ff0e-443b-d449-ed42587a75a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 548M/548M [00:04<00:00, 117MB/s]\n"]}]},{"cell_type":"markdown","source":["# TRENING"],"metadata":{"id":"MxtOV1FEu8Mv"}},{"cell_type":"markdown","source":["## Konfiguracja treningu\n","\n","parametry zaawansowane loss w argumentach domyslnych funkcji loss"],"metadata":{"id":"2ABv-ZdNvL-B"}},{"cell_type":"code","source":["epochs = 49\n","\n","train_load = False # True jesli chcemy wczytac model - wybierz checkpoint nizej\n","checkpoint_path_train = CHECKPOINTS_FOLDER + \"/model_11_17_16_1_14_48\""],"metadata":{"id":"LSvEpIuYvBvO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Inicjalizacja datasetu\n","odpowiednio ustawiony w argumentach podział danych"],"metadata":{"id":"fAmIq3GnvaTA"}},{"cell_type":"code","source":["dataset = HDRDataset(REFERENCE_DATASET_FOLDER, limit=127)\n","\n","loader = DataLoader(dataset, batch_size=1, shuffle=True)\n","\n","val_dataset = HDRDataset(REFERENCE_DATASET_FOLDER, from_file=127, limit=18)\n","\n","val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)"],"metadata":{"id":"t_lKckBMvOg0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TMONet().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)"],"metadata":{"id":"2sTxHRzqvjR0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if train_load:\n","  model.load_state_dict(torch.load(checkpoint_path_train, map_location=device))"],"metadata":{"id":"RxZ7tmTtxBcm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.makedirs(RESULTS_FOLDER, exist_ok=True)\n","os.makedirs(CHECKPOINTS_FOLDER, exist_ok=True)"],"metadata":{"id":"lvEnfaBVvg7h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Trenowanie"],"metadata":{"id":"grA8tLzNvdl_"}},{"cell_type":"code","source":["if train_model:\n","  for epoch in range(epochs):\n","      print(\"\")\n","      print(f\"Epoch {epoch}\")\n","      now = datetime.now()\n","      epoch_loss = 0.0\n","      step = 0\n","      brisque_list_train = []\n","\n","      # -------------------------\n","      # Trening\n","      for hdr_ulaw, hdr_rgb, fname in loader:\n","          step += 1\n","\n","          hdr_ulaw = hdr_ulaw.to(device)\n","          hdr_rgb = hdr_rgb.to(device)\n","\n","\n","\n","          imgs_exp = mul_exp(hdr_rgb)\n","          ldr_pred = model(imgs_exp[0], imgs_exp[1], imgs_exp[2])\n","\n","\n","          # dla loss (TYLKO dla loss) interpolujemy do mniejszej resolution dla optymalizacji zuzycia RAM\n","          #pred_small = F.interpolate(ldr_pred, scale_factor=0.25, mode='bilinear', align_corners=False)\n","          #hdr_ulaw = F.interpolate(hdr_ulaw, scale_factor=0.25, mode='bilinear', align_corners=False)\n","          pred_small = ldr_pred\n","\n","          loss = fcm_loss(pred_small, hdr_ulaw)\n","\n","          optimizer.zero_grad()\n","\n","          loss.backward()\n","\n","          optimizer.step()\n","\n","          epoch_loss += loss.item()\n","          img_out = ldr_pred[0].detach()  # (C,H,W)\n","\n","          #zapisanie obrazka\n","          img_out = torch.clamp(img_out, 0.0, 1.0)\n","          exten = f\"_{epoch}.png\"\n","          writeLDR(img_out, os.path.join(\n","              RESULTS_FOLDER,\n","              os.path.basename(fname[0]).replace(\".exr\", exten) ##UWAGA! Dodano zapisywanie po epoch, nie nadpisuja sie\n","          ))\n","\n","\n","          #if step % 10 == 0:\n","          #print(step, fname[0])\n","          #print(f\"Step {step}, Loss: {loss.item():.6f}\")\n","\n","          if isinstance(img_out, torch.Tensor):\n","              img_out = img_out.detach().cpu().numpy()\n","          # (C,H,W) -> (H,W,C)\n","          img_out = np.transpose(img_out, (1,2,0))\n","\n","          # clamp i 0-255\n","          img_out = np.clip(img_out, 0.0, 1.0)\n","          img_out = (img_out * 255).astype(np.uint8)\n","\n","          brisque_sdr = evaluate_image(img_out)\n","          #print(brisque_sdr)\n","          brisque_list_train.append(brisque_sdr)\n","\n","\n","      #zapisanie modelu\n","      now = datetime.now()\n","      model_name = f'model_{now.month}_{now.day}_{now.hour}_{now.minute}_{now.second}_{epoch}.pth'\n","      torch.save(model.state_dict(), CHECKPOINTS_FOLDER + \"/\" + model_name)\n","\n","      avg_loss = epoch_loss / step\n","      print(\"\")\n","      print(f\"Epoch {epoch} finished, Average Loss: {avg_loss:.6f}\")\n","      print(sum(brisque_list_train) / len(brisque_list_train))\n","\n","      # -------------------------\n","      # Walidacja - kontroluj! czy nie ma overfittingu\n","      if 'val_loader' in globals():  # tylko jeśli loader walidacyjny istnieje\n","          model.eval()\n","          val_loss = 0.0\n","          val_steps = 0\n","          br_list_val = []\n","          # nie uczymy\n","          with torch.no_grad():\n","              for val_ulaw, val_rgb, val_fname in val_loader:\n","                  val_steps += 1\n","                  val_ulaw = val_ulaw.to(device)\n","                  val_rgb = val_rgb.to(device)\n","\n","                  imgs_exp_val = mul_exp(val_rgb)\n","                  ldr_pred_val = model(imgs_exp_val[0], imgs_exp_val[1], imgs_exp_val[2])\n","                  # analogiczna optymalizacja dla RAM co w treningu\n","                  loss_val = fcm_loss(ldr_pred_val, val_ulaw)\n","                  val_loss += loss_val.item()\n","\n","                  img_out = ldr_pred_val[0].detach()  # (C,H,W)\n","\n","                  #zapisanie obrazka\n","                  img_out = torch.clamp(img_out, 0.0, 1.0)\n","\n","                  if isinstance(img_out, torch.Tensor):\n","                      img_out = img_out.detach().cpu().numpy()\n","                  # (C,H,W) -> (H,W,C)\n","                  img_out = np.transpose(img_out, (1,2,0))\n","\n","                  # clamp i 0-255\n","                  img_out = np.clip(img_out, 0.0, 1.0)\n","                  img_out = (img_out * 255).astype(np.uint8)\n","\n","                  brisque_sdr = evaluate_image(img_out)\n","                  #print(brisque_sdr)\n","                  br_list_val.append(brisque_sdr)\n","\n","\n","          avg_val_loss = val_loss / val_steps\n","          print(f\"Validation Loss after Epoch {epoch}: {avg_val_loss:.6f}\")\n","          print(sum(br_list_val) / len(br_list_val))\n","          model.train()"],"metadata":{"collapsed":true,"id":"AWx676TGS2xw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testowanie (zapisanie obrazów z sieci)\n","NIE KORZYSTA Z TEGO SAMEGO MODELU CO W TRENINGU! -> wczytaj wagi modelu w konfiguracji"],"metadata":{"id":"qLCAfs3Tlgsi"}},{"cell_type":"markdown","source":["## Konfiguracja testowania\n","USTAW MODEL (CHECKPOINT)!"],"metadata":{"id":"DR91aDrLx1h4"}},{"cell_type":"code","source":["checkpoint_path = CHECKPOINTS_FOLDER + \"/model_11_17_16_1_14_48.pth\""],"metadata":{"id":"p19Rxhvyx3XY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Inicjalizacja"],"metadata":{"id":"bveSI7DmxcNn"}},{"cell_type":"code","source":["test_dataset = HDRDataset(REFERENCE_DATASET_FOLDER, from_file=145, limit=36) # podział danych (zaczynamy od pliku indeks (nie nazwa!) 147 (wlacznie) max: 36 plików)\n","test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"],"metadata":{"id":"bAYlDgnQxe1-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TMONet().to(device) # wczytanie checkpointa odbywa się w sekcji predykcji"],"metadata":{"id":"13XAmYwMxh6O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.makedirs(RESULTS_FOLDER + '/TEST', exist_ok=True) # tutaj beda zapisane obrazki testowe"],"metadata":{"id":"vg4GcIGYxiB7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Predykcja\n","zapisywane są results z wytrenowanego modelu do RESULTS_FOLDER + '/TEST/'"],"metadata":{"id":"p8Wlhn-OyTaa"}},{"cell_type":"code","source":["if test_model and 'test_loader' in globals():  # tylko jeśli loader testowy istnieje\n","    model.load_state_dict(torch.load(checkpoint_path, map_location=device)) #wczytanie wag modelu\n","    model.eval()\n","    test_loss = 0.0\n","    test_steps = 0\n","    with torch.no_grad():\n","        for test_ulaw, test_rgb, test_fname in test_loader:\n","            print(f\"Predykcja: {test_fname[0]}\")\n","            test_steps += 1\n","            test_ulaw = test_ulaw.to(device)\n","            test_rgb = test_rgb.to(device)\n","\n","            imgs_exp_test = mul_exp(test_rgb)\n","            ldr_pred_test = model(imgs_exp_test[0], imgs_exp_test[1], imgs_exp_test[2])\n","\n","            img_out = ldr_pred_test[0].detach()  # (C,H,W)\n","\n","            img_out = torch.clamp(img_out, 0.0, 1.0)\n","            writeLDR(img_out, os.path.join(\n","                RESULTS_FOLDER + '/TEST',\n","                os.path.basename(test_fname[0]).replace(\".exr\", \".png\")\n","            ))\n","            print(f\"Zapisano: {test_fname[0]}\")\n","    model.train()"],"metadata":{"collapsed":true,"id":"22OnFUhQ8ea3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"38095100-9864-4842-890c-5616b1284cff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predykcja: /content/reference_dataset/195.exr\n","Zapisano: /content/reference_dataset/195.exr\n"]}]},{"cell_type":"markdown","source":["# Wyniki\n","Wymagane są rozpakowane dane z input_97, reference (hdr), oraz results (subfolder TEST)"],"metadata":{"id":"F0XzerdKljGJ"}},{"cell_type":"markdown","source":["## Inicjalizacja"],"metadata":{"id":"ms5I1Q6yyqdj"}},{"cell_type":"code","source":["# ZBIERAMY WSZYSTKIE SDR Z NASZEGO MODELU\n","sdr_paths = sorted(glob.glob(RESULTS_FOLDER + \"/TEST/*.png\"))\n","print(f\"Found {len(sdr_paths)} PNG files.\")\n","\n","count = 0"],"metadata":{"id":"2KwjfyZGytiR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0f09f677-cb62-46ea-82a1-bc4733f729cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 36 PNG files.\n"]}]},{"cell_type":"markdown","source":["## Obliczenie metryk"],"metadata":{"id":"IuN2XfQSzPjx"}},{"cell_type":"code","source":["if calc_metrics:\n","  brisque_reinhard_sum = 0.0\n","  ssim_reinhard_sum = 0.0\n","  brisque_mantiuk_sum = 0.0\n","  ssim_mantiuk_sum = 0.0\n","  brisque_sdr_sum = 0.0\n","  ssim_sdr_sum = 0.0\n","  brisque_input97_sum = 0.0\n","  ssim_input97_sum = 0.0\n","\n","  count = 0\n","\n","  for path in sdr_paths:\n","\n","      base = os.path.splitext(os.path.basename(path))[0]   # np '006'\n","      hdr_path = os.path.join(REFERENCE_DATASET_FOLDER, base + \".exr\")\n","\n","      print(f\"\\nProcessing SDR: {path}\")\n","      print(f\"Matching HDR:   {hdr_path}\")\n","\n","      hdr = read_exr(hdr_path)\n","      if hdr is None:\n","          print(\"Could not load HDR!\")\n","          continue\n","      hdr = cv2.resize(hdr, (255, 255), interpolation=cv2.INTER_AREA) # do 255\n","\n","      # ------------------------------\n","      # SDR z input_97\n","      input97_path = os.path.join(INPUT_97_DATASET_FOLDER, base + \".png\")\n","\n","      sdr_in = cv2.imread(input97_path, cv2.IMREAD_COLOR)\n","      sdr_in = cv2.resize(sdr_in, (255, 255), interpolation=cv2.INTER_AREA) # do 255\n","\n","\n","      sdr_in_rgb = cv2.cvtColor(sdr_in, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n","      brisque_in = evaluate_image(sdr_in_rgb)\n","      ssim_in = ssim(sdr_in_rgb, sdr_in_rgb, channel_axis=2, data_range=1.0)\n","      ssim_in = np.nan_to_num(ssim_in, nan=1.0)\n","      brisque_input97_sum += brisque_in\n","      ssim_input97_sum += ssim_in\n","      print(\"BRISQUE (input_97):\", brisque_in)\n","      print(f\"SSIM (HDR vs input_97): {ssim_in}\")\n","\n","\n","      # ------------------------------\n","      # Reinhard tonemap\n","      ldr_reinhard = tone_map_reinhard(hdr)\n","      ldr_reinhard = ldr_reinhard[..., ::-1]    # BGR → RGB\n","      ldr_reinhard = np.clip(ldr_reinhard, 0, 1)\n","      brisque_reinhard = evaluate_image(ldr_reinhard)\n","      ssim_reinhard = ssim(sdr_in_rgb, ldr_reinhard, channel_axis=2, data_range=1.0)\n","      ssim_reinhard = np.nan_to_num(ssim_reinhard, nan=1.0)\n","      brisque_reinhard_sum += brisque_reinhard\n","      ssim_reinhard_sum += ssim_reinhard\n","      print(\"BRISQUE (HDR→Reinhard):\", brisque_reinhard)\n","      print(\"SSIM (HDR vs Reinhard):\", ssim_reinhard)\n","\n","      # ------------------------------\n","      # Mantiuk tonemap\n","      ldr_mantiuk = tone_map_mantiuk(hdr)\n","      ldr_mantiuk = ldr_mantiuk[..., ::-1]    # BGR → RGB\n","      ldr_mantiuk = np.clip(ldr_mantiuk, 0, 1)\n","      brisque_mantiuk = evaluate_image(ldr_mantiuk)\n","      ssim_mantiuk = ssim(sdr_in_rgb, ldr_mantiuk, channel_axis=2, data_range=1.0)\n","      ssim_mantiuk = np.nan_to_num(ssim_mantiuk, nan=1.0)\n","      brisque_mantiuk_sum += brisque_mantiuk\n","      ssim_mantiuk_sum += ssim_mantiuk\n","      print(\"BRISQUE (HDR→Mantiuk):\", brisque_mantiuk)\n","      print(\"SSIM (HDR vs Mantiuk):\", ssim_mantiuk)\n","\n","      # ------------------------------\n","      # SDR z wytrenowanej sieci\n","      ldr_net = cv2.imread(path, cv2.IMREAD_COLOR)\n","      if ldr_net is None:\n","          print(\"Could not load PNG!\")\n","          continue\n","      ldr_rgb = cv2.cvtColor(ldr_net, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n","      brisque_sdr = evaluate_image(ldr_rgb)\n","      ssim_sdr = ssim(sdr_in_rgb, ldr_rgb, channel_axis=2, data_range=1.0)\n","      ssim_sdr = np.nan_to_num(ssim_sdr, nan=1.0)\n","      brisque_sdr_sum += brisque_sdr\n","      ssim_sdr_sum += ssim_sdr\n","      print(\"BRISQUE (SDR→net(ours)):\", brisque_sdr)\n","      print(f\"SSIM (HDR vs SDR net(ours)): {ssim_sdr}\")\n","\n","      count += 1"],"metadata":{"collapsed":true,"id":"50TC5vSWBzfS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"012846ac-8d20-4ae0-eebc-9ad6177e0cdf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/156.png\n","Matching HDR:   /content/reference_dataset/156.exr\n","BRISQUE (input_97): 35.053816254917564\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 65.45751104655758\n","SSIM (HDR vs Reinhard): 1.0\n","BRISQUE (HDR→Mantiuk): 140.52460398304393\n","SSIM (HDR vs Mantiuk): 0.16780096\n","BRISQUE (SDR→net(ours)): 29.107933770682138\n","SSIM (HDR vs SDR net(ours)): 0.5659149885177612\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/158.png\n","Matching HDR:   /content/reference_dataset/158.exr\n","BRISQUE (input_97): 10.762808262406196\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 19.781952611413402\n","SSIM (HDR vs Reinhard): 0.6275952\n","BRISQUE (HDR→Mantiuk): 139.60669297770696\n","SSIM (HDR vs Mantiuk): 0.08194793\n","BRISQUE (SDR→net(ours)): 6.3654018647829105\n","SSIM (HDR vs SDR net(ours)): 0.5466247200965881\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/159.png\n","Matching HDR:   /content/reference_dataset/159.exr\n","BRISQUE (input_97): 4.365971483123502\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 41.0954353123133\n","SSIM (HDR vs Reinhard): 1.0\n","BRISQUE (HDR→Mantiuk): 115.70217563827842\n","SSIM (HDR vs Mantiuk): 0.040629525\n","BRISQUE (SDR→net(ours)): 18.20876422276146\n","SSIM (HDR vs SDR net(ours)): 0.8340733051300049\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/160.png\n","Matching HDR:   /content/reference_dataset/160.exr\n","BRISQUE (input_97): -0.010492803940366002\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 50.827377446670795\n","SSIM (HDR vs Reinhard): 1.0\n","BRISQUE (HDR→Mantiuk): 96.45051976465552\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 5.367328716852711\n","SSIM (HDR vs SDR net(ours)): 0.8890647292137146\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/161.png\n","Matching HDR:   /content/reference_dataset/161.exr\n","BRISQUE (input_97): 28.028124621452633\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 35.7531585949765\n","SSIM (HDR vs Reinhard): 0.9118534\n","BRISQUE (HDR→Mantiuk): 80.05484374631558\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 29.75439935044571\n","SSIM (HDR vs SDR net(ours)): 0.8856160044670105\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/162.png\n","Matching HDR:   /content/reference_dataset/162.exr\n","BRISQUE (input_97): 12.456116752930114\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 15.20956521578168\n","SSIM (HDR vs Reinhard): 0.58772904\n","BRISQUE (HDR→Mantiuk): 85.45510221421782\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 11.6297649883073\n","SSIM (HDR vs SDR net(ours)): 0.5168707966804504\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/163.png\n","Matching HDR:   /content/reference_dataset/163.exr\n","BRISQUE (input_97): 1.838099496231024\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 24.119647979143878\n","SSIM (HDR vs Reinhard): 0.85617733\n","BRISQUE (HDR→Mantiuk): 60.200923800899744\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 7.620994196870555\n","SSIM (HDR vs SDR net(ours)): 0.8137059211730957\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/164.png\n","Matching HDR:   /content/reference_dataset/164.exr\n","BRISQUE (input_97): -3.0701180270831685\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 29.2237115704647\n","SSIM (HDR vs Reinhard): 1.0\n","BRISQUE (HDR→Mantiuk): 39.10068817267191\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 5.960549718917463\n","SSIM (HDR vs SDR net(ours)): 0.6552571654319763\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/165.png\n","Matching HDR:   /content/reference_dataset/165.exr\n","BRISQUE (input_97): 2.8582266866397674\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 4.574799657640341\n","SSIM (HDR vs Reinhard): 1.0\n","BRISQUE (HDR→Mantiuk): 59.80184330226777\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 3.416011975024361\n","SSIM (HDR vs SDR net(ours)): 0.5165590643882751\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/166.png\n","Matching HDR:   /content/reference_dataset/166.exr\n","BRISQUE (input_97): 26.27706177760544\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 39.818518561461445\n","SSIM (HDR vs Reinhard): 1.0\n","BRISQUE (HDR→Mantiuk): 76.66790345328556\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 18.782421141247113\n","SSIM (HDR vs SDR net(ours)): 0.628902018070221\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/167.png\n","Matching HDR:   /content/reference_dataset/167.exr\n","BRISQUE (input_97): 8.844530289462995\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 30.834959662515445\n","SSIM (HDR vs Reinhard): 1.0\n","BRISQUE (HDR→Mantiuk): 80.18044164464695\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 11.03779956848095\n","SSIM (HDR vs SDR net(ours)): 0.6250346899032593\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/168.png\n","Matching HDR:   /content/reference_dataset/168.exr\n","BRISQUE (input_97): 8.700666532700865\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 12.897218871460808\n","SSIM (HDR vs Reinhard): 0.9425052\n","BRISQUE (HDR→Mantiuk): 120.68903087828048\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 6.7933562963227985\n","SSIM (HDR vs SDR net(ours)): 0.9057770371437073\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/169.png\n","Matching HDR:   /content/reference_dataset/169.exr\n","BRISQUE (input_97): 21.63534728241936\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 51.21549362701174\n","SSIM (HDR vs Reinhard): 1.0\n","BRISQUE (HDR→Mantiuk): 118.03886287371009\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 16.73334088156261\n","SSIM (HDR vs SDR net(ours)): 0.895519495010376\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/170.png\n","Matching HDR:   /content/reference_dataset/170.exr\n","BRISQUE (input_97): 12.048602894988761\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 37.03865158610094\n","SSIM (HDR vs Reinhard): 1.0\n","BRISQUE (HDR→Mantiuk): 133.84733680290933\n","SSIM (HDR vs Mantiuk): 0.03165322\n","BRISQUE (SDR→net(ours)): 9.315487806722757\n","SSIM (HDR vs SDR net(ours)): 0.7184043526649475\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/171.png\n","Matching HDR:   /content/reference_dataset/171.exr\n","BRISQUE (input_97): 26.917882978145457\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 47.68029289847132\n","SSIM (HDR vs Reinhard): 1.0\n","BRISQUE (HDR→Mantiuk): 53.26514561008335\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 24.663633118492584\n","SSIM (HDR vs SDR net(ours)): 0.6371545195579529\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/172.png\n","Matching HDR:   /content/reference_dataset/172.exr\n","BRISQUE (input_97): 25.129930537388276\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 35.337987235465306\n","SSIM (HDR vs Reinhard): 0.65999246\n","BRISQUE (HDR→Mantiuk): 52.862100641822025\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 20.859468735236504\n","SSIM (HDR vs SDR net(ours)): 0.5525609850883484\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/173.png\n","Matching HDR:   /content/reference_dataset/173.exr\n","BRISQUE (input_97): 15.5604747863633\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 21.42343589148649\n","SSIM (HDR vs Reinhard): 0.5046435\n","BRISQUE (HDR→Mantiuk): 74.34381787092244\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 18.096163924086994\n","SSIM (HDR vs SDR net(ours)): 0.4738806486129761\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/174.png\n","Matching HDR:   /content/reference_dataset/174.exr\n","BRISQUE (input_97): 35.03489678640696\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 45.67466034792844\n","SSIM (HDR vs Reinhard): 0.89040965\n","BRISQUE (HDR→Mantiuk): 69.883384289259\n","SSIM (HDR vs Mantiuk): 0.14346336\n","BRISQUE (SDR→net(ours)): 28.08844088370276\n","SSIM (HDR vs SDR net(ours)): 0.8271473050117493\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/175.png\n","Matching HDR:   /content/reference_dataset/175.exr\n","BRISQUE (input_97): 26.165720257343963\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 38.26542538457451\n","SSIM (HDR vs Reinhard): 0.71499944\n","BRISQUE (HDR→Mantiuk): 86.9769491765002\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 27.581079449805742\n","SSIM (HDR vs SDR net(ours)): 0.5012110471725464\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/176.png\n","Matching HDR:   /content/reference_dataset/176.exr\n","BRISQUE (input_97): 5.1972058835300174\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 11.581063097839518\n","SSIM (HDR vs Reinhard): 0.5598868\n","BRISQUE (HDR→Mantiuk): 28.858622758969403\n","SSIM (HDR vs Mantiuk): 0.5444731\n","BRISQUE (SDR→net(ours)): 6.604976339679723\n","SSIM (HDR vs SDR net(ours)): 0.429281622171402\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/177.png\n","Matching HDR:   /content/reference_dataset/177.exr\n","BRISQUE (input_97): 12.234822999804436\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 17.41249983074735\n","SSIM (HDR vs Reinhard): 0.42957008\n","BRISQUE (HDR→Mantiuk): 87.86155758847283\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 9.174665868879487\n","SSIM (HDR vs SDR net(ours)): 0.40812209248542786\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/178.png\n","Matching HDR:   /content/reference_dataset/178.exr\n","BRISQUE (input_97): 21.531619878008286\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 39.60479048326661\n","SSIM (HDR vs Reinhard): 1.0\n","BRISQUE (HDR→Mantiuk): 115.50206588959182\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 24.55516279641219\n","SSIM (HDR vs SDR net(ours)): 0.8119960427284241\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/179.png\n","Matching HDR:   /content/reference_dataset/179.exr\n","BRISQUE (input_97): 19.500160231468016\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 29.5681133911896\n","SSIM (HDR vs Reinhard): 0.94087034\n","BRISQUE (HDR→Mantiuk): 41.243034428627055\n","SSIM (HDR vs Mantiuk): 0.44936433\n","BRISQUE (SDR→net(ours)): 19.705855968923146\n","SSIM (HDR vs SDR net(ours)): 0.9204707741737366\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/180.png\n","Matching HDR:   /content/reference_dataset/180.exr\n","BRISQUE (input_97): 24.08257563753679\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 41.26454453456236\n","SSIM (HDR vs Reinhard): 1.0\n","BRISQUE (HDR→Mantiuk): 76.34903783955306\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 27.363577376941606\n","SSIM (HDR vs SDR net(ours)): 0.8277717232704163\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/181.png\n","Matching HDR:   /content/reference_dataset/181.exr\n","BRISQUE (input_97): 1.5023024644548002\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 5.3825906020123\n","SSIM (HDR vs Reinhard): 0.70883566\n","BRISQUE (HDR→Mantiuk): 19.952072143518734\n","SSIM (HDR vs Mantiuk): 0.6762555\n","BRISQUE (SDR→net(ours)): -7.744280117917953\n","SSIM (HDR vs SDR net(ours)): 0.5916908979415894\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/182.png\n","Matching HDR:   /content/reference_dataset/182.exr\n","BRISQUE (input_97): -8.243577485776115\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 2.355431169074649\n","SSIM (HDR vs Reinhard): 0.94369316\n","BRISQUE (HDR→Mantiuk): 24.353749681728658\n","SSIM (HDR vs Mantiuk): 0.50879556\n","BRISQUE (SDR→net(ours)): -8.817267132974877\n","SSIM (HDR vs SDR net(ours)): 0.8541877865791321\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/183.png\n","Matching HDR:   /content/reference_dataset/183.exr\n","BRISQUE (input_97): 44.90915728192837\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 62.64418891923728\n","SSIM (HDR vs Reinhard): 0.94850296\n","BRISQUE (HDR→Mantiuk): 102.24037052010871\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 44.915567963216375\n","SSIM (HDR vs SDR net(ours)): 0.9465174674987793\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/184.png\n","Matching HDR:   /content/reference_dataset/184.exr\n","BRISQUE (input_97): 51.37726963218617\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 98.26934002332317\n","SSIM (HDR vs Reinhard): 1.0\n","BRISQUE (HDR→Mantiuk): 115.08008089096623\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 58.160976965703725\n","SSIM (HDR vs SDR net(ours)): 0.6793253421783447\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/185.png\n","Matching HDR:   /content/reference_dataset/185.exr\n","BRISQUE (input_97): 24.37255788889408\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 72.61566030434884\n","SSIM (HDR vs Reinhard): 1.0\n","BRISQUE (HDR→Mantiuk): 66.51249434358292\n","SSIM (HDR vs Mantiuk): 0.8373577\n","BRISQUE (SDR→net(ours)): 31.537300315754095\n","SSIM (HDR vs SDR net(ours)): 0.3894393742084503\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/187.png\n","Matching HDR:   /content/reference_dataset/187.exr\n","BRISQUE (input_97): -6.693446242219608\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 12.000132181580142\n","SSIM (HDR vs Reinhard): 0.73858505\n","BRISQUE (HDR→Mantiuk): 78.14197426021107\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): -6.23125759380801\n","SSIM (HDR vs SDR net(ours)): 0.5619005560874939\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/190.png\n","Matching HDR:   /content/reference_dataset/190.exr\n","BRISQUE (input_97): 10.77338259920586\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 8.239902668805684\n","SSIM (HDR vs Reinhard): 0.4843742\n","BRISQUE (HDR→Mantiuk): 53.71784963785754\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): -0.09451674316690628\n","SSIM (HDR vs SDR net(ours)): 0.39787769317626953\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/191.png\n","Matching HDR:   /content/reference_dataset/191.exr\n","BRISQUE (input_97): 41.248367612784676\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 66.1711576945797\n","SSIM (HDR vs Reinhard): 0.94802237\n","BRISQUE (HDR→Mantiuk): 108.35782301980842\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 54.98458997994871\n","SSIM (HDR vs SDR net(ours)): 0.8737069964408875\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/192.png\n","Matching HDR:   /content/reference_dataset/192.exr\n","BRISQUE (input_97): 44.17571010726496\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 76.31106590110002\n","SSIM (HDR vs Reinhard): 0.91194075\n","BRISQUE (HDR→Mantiuk): 101.60897924870241\n","SSIM (HDR vs Mantiuk): 0.3788991\n","BRISQUE (SDR→net(ours)): 61.90665319434865\n","SSIM (HDR vs SDR net(ours)): 0.7570833563804626\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/193.png\n","Matching HDR:   /content/reference_dataset/193.exr\n","BRISQUE (input_97): 22.62984300762318\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 38.40553678138028\n","SSIM (HDR vs Reinhard): 0.79424566\n","BRISQUE (HDR→Mantiuk): 104.90464597476941\n","SSIM (HDR vs Mantiuk): 0.17204057\n","BRISQUE (SDR→net(ours)): 23.014656957785945\n","SSIM (HDR vs SDR net(ours)): 0.5621652007102966\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/194.png\n","Matching HDR:   /content/reference_dataset/194.exr\n","BRISQUE (input_97): 29.702796502866676\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 41.98974101084784\n","SSIM (HDR vs Reinhard): 0.6241166\n","BRISQUE (HDR→Mantiuk): 77.77738955686553\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 21.09396491837967\n","SSIM (HDR vs SDR net(ours)): 0.4994729459285736\n","\n","Processing SDR: /content/drive/MyDrive/SIGK_P2/resultsV5/TEST/195.png\n","Matching HDR:   /content/reference_dataset/195.exr\n","BRISQUE (input_97): 38.36838843416908\n","SSIM (HDR vs input_97): 1.0\n","BRISQUE (HDR→Reinhard): 77.3103406427343\n","SSIM (HDR vs Reinhard): 0.4834875\n","BRISQUE (HDR→Mantiuk): 98.05801243538141\n","SSIM (HDR vs Mantiuk): 1.0\n","BRISQUE (SDR→net(ours)): 51.371689407477305\n","SSIM (HDR vs SDR net(ours)): 0.2978014051914215\n"]}]},{"cell_type":"markdown","source":["## Wyświetlenie metryk"],"metadata":{"id":"7xAQ4Bew3B7j"}},{"cell_type":"code","source":["# -------------------------------------------------------\n","# ŚREDNIE\n","if count > 0:\n","    print(\"\\n=============================================\")\n","    print(\"                 AVERAGE METRICS\")\n","    print(f\"Files processed: {count}\")\n","\n","    print(\"\\n--- Reinhard ---\")\n","    print(\"Average BRISQUE:\", brisque_reinhard_sum / count)\n","    print(\"Average SSIM:   \", ssim_reinhard_sum / count)\n","\n","    print(\"\\n--- Mantiuk ---\")\n","    print(\"Average BRISQUE:\", brisque_mantiuk_sum / count)\n","    print(\"Average SSIM:   \", ssim_mantiuk_sum / count)\n","\n","    print(\"\\n--- SDR (network output (ours)) ---\")\n","    print(\"Average BRISQUE:\", brisque_sdr_sum / count)\n","    print(\"Average SSIM:   \", ssim_sdr_sum / count)\n","\n","    print(\"\\n--- SDR (input_97) ---\")\n","    print(\"Average BRISQUE:\", brisque_input97_sum / count)\n","    print(\"Average SSIM:   \", ssim_input97_sum / count)\n","else:\n","    print(\"No files processed!\")"],"metadata":{"id":"ZskZU1YuzJh7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ea10a87d-df1b-4024-defa-b18ada7cff3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=============================================\n","                 AVERAGE METRICS\n","Files processed: 36\n","\n","--- Reinhard ---\n","Average BRISQUE: 37.426552853835226\n","Average SSIM:    0.8392232\n","\n","--- Mantiuk ---\n","Average BRISQUE: 82.89367019611646\n","Average SSIM:    0.77868557\n","\n","--- SDR (network output (ours)) ---\n","Average BRISQUE: 19.7467960298858\n","Average SSIM:    0.6610581\n","\n","--- SDR (input_97) ---\n","Average BRISQUE: 18.75741120231202\n","Average SSIM:    1.0\n"]}]},{"cell_type":"markdown","source":["# Porównanie wizualne\n","Dla podanego pliku w zmiennej file_base (sekcja Wizualizacja) -> generowane są pliki w COMPARE_FOLDER\n","\n","pliki z sufiksami dla każdej metody\n","\n","HDR_norm uzywane dla SSIM jako obraz referencyjny"],"metadata":{"id":"6wjI19Dx3HvD"}},{"cell_type":"markdown","source":["## Inicjalizacja\n"],"metadata":{"id":"tP2fYi6H4Dpi"}},{"cell_type":"code","source":["os.makedirs(COMPARE_FOLDER, exist_ok=True)"],"metadata":{"id":"Jl9VZvIF4CyB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Wizualizacja\n"],"metadata":{"id":"bClzVhYp4IjI"}},{"cell_type":"code","source":["test_dir = os.path.join(RESULTS_FOLDER, \"TEST\")\n","png_files = sorted([f for f in os.listdir(test_dir) if f.endswith(\".png\")])\n","\n","for png in png_files:\n","    file_base = os.path.splitext(png)[0]   # np. \"173\"\n","\n","    hdr_path = os.path.join(REFERENCE_DATASET_FOLDER, file_base + \".exr\")\n","    sdr_net_path = os.path.join(test_dir, file_base + \".png\")\n","    sdr_input97_path = os.path.join(INPUT_97_DATASET_FOLDER, file_base + \".png\")\n","\n","    hdr = read_exr(hdr_path)\n","    hdr = cv2.resize(hdr, (255, 255), interpolation=cv2.INTER_AREA)\n","\n","    ldr_reinhard = tone_map_reinhard(hdr)\n","    ldr_reinhard = ldr_reinhard[..., ::-1]\n","    ldr_reinhard = np.clip(ldr_reinhard, 0, 1)\n","\n","    ldr_mantiuk = tone_map_mantiuk(hdr)\n","    ldr_mantiuk = ldr_mantiuk[..., ::-1]\n","    ldr_mantiuk = np.clip(ldr_mantiuk, 0, 1)\n","\n","    ldr_net = cv2.imread(sdr_net_path, cv2.IMREAD_COLOR)\n","    ldr_net = cv2.cvtColor(ldr_net, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n","    ldr_net = cv2.resize(ldr_net, (255, 255), interpolation=cv2.INTER_AREA)\n","\n","    if os.path.exists(sdr_input97_path):\n","        sdr_input97 = cv2.imread(sdr_input97_path, cv2.IMREAD_COLOR)\n","        sdr_input97 = cv2.cvtColor(sdr_input97, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n","        sdr_input97 = cv2.resize(sdr_input97, (255, 255), interpolation=cv2.INTER_AREA)\n","    else:\n","        sdr_input97 = np.zeros_like(ldr_net)\n","\n","    def show_img(window_name, img):\n","        filename = f\"{file_base}_{window_name}.png\"\n","        img_to_save = np.clip(img, 0.0, 1.0).astype(np.float32)\n","        img_to_save = np.transpose(img_to_save, (2,0,1))\n","        writeLDR(img_to_save, os.path.join(COMPARE_FOLDER, filename))\n","        print(f\"Saved: {filename}\")\n","\n","    hdr_rgb = hdr[..., ::-1]\n","    hdr_rgb = np.clip(hdr_rgb, 0, 1)\n","\n","    show_img(\"HDR\", hdr_rgb)\n","    show_img(\"Reinhard\", ldr_reinhard)\n","    show_img(\"Mantiuk\", ldr_mantiuk)\n","    show_img(\"SDR_net\", ldr_net)\n","    show_img(\"SDR_input97\", sdr_input97)\n","\n","    # MOZAIKA 2×2\n","    tile_size = 255\n","    canvas = np.zeros((tile_size * 2, tile_size * 2, 3), dtype=np.float32)\n","    #mantiuk - reinhard\n","    #net - input_97\n","    canvas[0:255, 0:255] = ldr_mantiuk\n","    canvas[0:255, 255:510] = ldr_reinhard\n","    canvas[255:510, 0:255] = ldr_net\n","    canvas[255:510, 255:510] = sdr_input97\n","\n","    mosaic_name = f\"COMPARE_GRID_{file_base}.png\"\n","    mosaic_save = np.transpose(canvas, (2,0,1))\n","    writeLDR(mosaic_save, os.path.join(COMPARE_FOLDER, mosaic_name))\n","\n","    print(\"Saved mosaic:\", mosaic_name)\n"],"metadata":{"collapsed":true,"id":"n2k7WLoOLNTI","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"0f497dc2-0077-4376-dac5-f97817eeb983"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hdr min/max: 1.513958e-05 65504.0\n","hdr_norm   min/max: 2.3112451e-10 1.0\n","hdr mean/std: 61.99152 650.0394\n","hdr_norm   mean/std: 0.0010419395 0.010564659\n","25.00681556322465\n","97.30552713939394\n","Reinhard min/max: 3.801958e-11 1.0\n","Mantiuk   min/max: nan nan\n","Reinhard mean/std: 0.34068573 0.20764497\n","Mantiuk   mean/std: nan nan\n"]},{"output_type":"error","ename":"error","evalue":"OpenCV(4.12.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-977815115.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# 4. SDR sieci\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mldr_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdr_net_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mldr_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldr_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# 5. SDR z input_97\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.12.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"]}]}]}